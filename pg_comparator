#! /usr/local/bin/perl -w
#
# $Id: pg_comparator 239 2004-08-31 11:46:18Z coelho $
#
# HELP 1: pg_comparator --man
# HELP 2: pod2text pg_comparator
# HELP 3: read pod stuff bellow with your favorite viewer
#

=head1 NAME

B<pg_comparator> - network and time efficient table content comparison.

=head1 SYNOPSIS

B<pg_comparator> [options as B<--help> B<--option> B<--man>] conn1 conn2

=head1 DESCRIPTION

This script performs a network and time efficient comparison of two
possibly large tables on two servers. It makes only sense to use it
if the expected differences are small.

The implementation is quite generic: multi-column keys, no assumption
of data types other that they can be cast to text, subset of columns
can be used for the comparison, handling of null values...

=head1 OPTIONS

Options allow to request help or to adjust some internal parameters.
Short one-letter options are also available, usually with the first letter
of the option name.

=over 4

=item C<--aggregate=xor>

Aggregation function to be used for summaries.
Must operate on the result of the checksum function.

=item C<--ask-pass>

Ask for passwords interactively.

=item C<--checksum=cksum8>

Checksum function to be used. The quality of this function in term
of bit-spreading and uniformity is important for the quality of the
results. A poor function might miss differences because of collisions
or result in a more costly search. Cryptographic hash functions such as 
MD5 or SHA1 are a good choice.

=item C<--factor=128>

Folding factor: the number of rows grouped together at each stage.
Default chosen after some basic tests on medium-size cases.

=item C<--help>

Show short help.

=item C<--man>

Show manual page.

=item C<--max=32>

Maximum search effort, search will stop if above: it gives up if a 
single query at any level involves more than this many differences. 
Use 0 for no limit.

=item C<--null="null_string(%s,'null')">

String processing template to take care of null values.
If you set --null='%s', null values are set as they appear,
which might damage the results in null columns are used because 
multi-column checksums will all be 0.

=item C<--option>

Show option summary.

=item C<--prefix=cmp>

Name prefix for comparison tables. May be schema-qualified.

=item C<--separator=:>

Separator string when concatenating columns.

=item C<--show-all-keys --noshow-all-keys>

Show all differing keys, even if big chunks of INSERT and DELETE are detected. 
This should not happend under the "few" differences assumption and with k<<f.
Default is not to show all keys.

=item C<--source='DBI:Pg:dbname=%b;host=%h;port=%p;'>

DBI source template. Changing this might allow to use this command 
with another type of database, as the SQL used is quite standard.
Tags are interpreted as follow: %b is base, %h is host, %p is port, %u 
is login.

=item C<--temporary --notemporary>

Whether to use temporary tables. Default is to use.
If you don't, the tables are kept at the end, so they will have
to be deleted by hand.

=item C<--verbose>

Be verbose about what is happening. The more you ask, the more verbose.

=back

=head1 ARGUMENTS

The two arguments describe database connections with the following URL-like
syntax, where square brackets denote optional parts. Although all parts
are optional, the arguments must not be empty!

  [db:][login[:pass]@][host[:port]][[/base]/[schema.]table[?[key:]cols]]

=over 4

=item B<login>

Login to use when connecting to database. Default is username.

=item B<pass>

Password to use when connecting to database. Default is none.

=item B<host>

Hostname to connect to. Default is localhost.

=item B<port>

Tcp-ip port to connect to. Default is 5432.

=item B<base>

Database catalog to connect to. Default is username.

=item B<schema.table>

The possibly schema-qualified table to use for comparison.
Default is same as first connection.

=item B<keys>

Comma-separated list of key columns. Default is same as first connection.

=item B<cols>

Comma-separated list of columns to compare. Default is same as first 
connection.

=back

=head1 OUTPUT

The output of the command consists of lines describing the differences
found between the two tables. They are expressed in term of insertions,
updates or deletes and of tuple keys.

=over 4

=item B<UPDATE k>

Key I<k> tuple was updated between table 1 to 2.
The tuple exists in both tables with different values.

=item B<DELETE k>

Key I<k> tuple was deleted in table 2, assuming table 1 as the reference.
The tuple only appears in table 1.

=item B<INSERT k>

Key I<k> tuple was inserted into table 2, assuming table 1 as the reference.
The tuple only appears in table 2.

=back

In case of key-checksum or data-checksum collision, false positive or
false negative results may occur. Changing the checksum function would
help in such cases.

In very rare cases, the output gives an idc instead of a key. This
is because there are so many differences that the summary of one group
appears to be empty on one side... Consider option B<--show-all-keys> 
and B<--max> to display all offending keys instead, but be warn that 
the result will be large.

=head1 DEPENDENCES

Three support functions are needed on the database:

=over 2

=item 1

The C<null_string> function takes care of NULL values in columns.
It may be changed with the B<--null> option.

A suitable implementation is available for PostgreSQL and can be loaded
into the server by processing C<share/contrib/null_string.sql>.

=item 2

A checksum function must be used to reduce and distribute key
and columns values. 
It may be changed with the B<--checksum> option.

Three suitable implementations are available for PostgreSQL and can be loaded
into the server by processing C<share/contrib/checksum.sql>.
The three functions C<cksum2>, C<cksum4> and C<cksum8> differ on the size
of the resulting checksum expressed in bytes. The default is to use
the C<cksum8> version.

=item 3

An aggregate function is used to summarize checksums for a range of rows. 
It must operate on the result of the checksum function.
It may be changed with the B<--aggregate> option.

Suitable implementations of a exclusive-or C<xor> aggregate are available 
for PostgreSQL and can be loaded into the server by processing 
C<share/contrib/xor_aggregate.sql>.

=back

Moreover several perl modules are useful to run this script:

=over 4

=item 

C<Getopt::Long> for option management.

=item

C<DBI> and C<DBD::Pg> to connect to PostgreSQL.

=item

C<Term::ReadPassword> for ask-pass option.

=item

C<Pod::Usage> for doc self-extraction (--man --opt --help).

=back

=head1 EXAMPLES

Compare tables calvin and hobbes in default database on localhost, 
with key I<id> and columns I<c1> and I<c2>:

    ./pg_comparator /calvin?id:c1,c2 /hobbes

Compare tables calvin in default database on localhost and the same
table in default database on sablons, with key I<id> and column I<data>:

    ./pg_comparator localhost/calvin?id:data sablons

=head1 ALGORITHM

The aim of the algorithm is to compare the content of two tables,
possibly on different remote servers, with minimum network traffic.
It is performed in three phases. 

=over 2

=item 1 

A checksum table is computed on each side for the target table.

=item 2 

A fist level summary table is computed on each side by aggregating chunks
of the checksum table. Other levels of summary aggregations are then performed
till there is only one row in the last table, which then stores a 
global checksum for the whole initial target tables. 

=item 3 

Starting from the upper summary tables, aggregated checksums are compared 
from both sides to look for differences, down to the initial checksum table.
Keys of differing tuples are displayed.

=back

=head2 CHECKSUM TABLE

The first phase computes the initial cheksum table I<t(0)> on each side.
Assuming that I<key> is the table key columns, and I<cols> is the
table data columns that are to be checked for differences, then
it is performed by querying target table I<t> as follow:

  CREATE TABLE t(0) AS
  SELECT key AS id, checksum(key) AS idc, checksum(key || cols) AS cks
  FROM t;

The inititial key is kept, as it will be used to show differing keys
at the end. The rational for the I<idc> column is to randomize the 
key-values distribution so as to balance aggrates in the next phase.
The key must appear in the cheksum also, otherwise content exchanged 
between two keys would not be detected in some cases.

=head2 SUMMARY TABLES

Now we compute a set of cascading summary tables by grouping I<f>
(folding factor) checksums together at each stage. The grouping is
based on a modulo on the I<idc> column to take advantage of the 
checksum randomization. Starting from I<p=0> we build:

  CREATE TABLE t(p+1) AS
  SELECT MOD(idc, module(p+1)) AS idc, XOR(cks)
  FROM t(p)
  GROUP BY MOD(idc, module(p+1));

The module(p) is defined so that it groups together on average I<f>
checksums together: module(0) = size; module(p) = module(p-1)/f;
This leads to a hierarchy of tables, each one being a smaller summary
of the previous one:

=over 4

=item level B<0>

checksum table, I<size> rows, i.e. as many rows as the target table.

=item level B<1>

first summary table, (size/f) rows.

=item level B<p>

intermediate summary table, (size/f**p) rows.

=item level B<n-1>

one before last summary table, less than f rows.

=item level B<n>

last summary table, 1 row.

=back

It is important that the very same modules are used so that aggregations
are the same, allowing to compare matching contents on both sides.

=head2 SEARCH FOR DIFFERENCES

After all these support tables are built on both sides comes the search for
differences. When checking the checksum summary of the last tables (level I<n>)
with only one row, it is basically a comparison of the cheksum of the 
whole table contents. If they match, then both tables are equal, 
and we are done. Otherwise, if these checksums differ, some investigation 
is needed to detect offending keys.

The investigation is performed by going down the table hierarchy and
looking for all I<idc> for which there was a difference in the checksum
on the previous level. The same query is performed on both side
at each stage:

  SELECT idc, cks
  FROM t(p)
  WHERE MOD(idc, module(p+1)) IN
     (idc-with-differing-checksums-from-previous-level-p+1)
  ORDER BY idc, cks;

And the results from both sides are merged together. 
When doing the merge procedure, four cases can arise:

=over 2

=item 1

Both I<idc> and I<cks> match. Then there is no difference.

=item 2

Although I<idc> does match, I<cks> does not. Then this I<idc> is
to be investigated at the next level, as the checksum summary differs.
If we are already at the last level, then the offending key can be shown.

=item 3

No I<idc> match, one supplemental I<idc> in the first side.
Then this I<idc> correspond to key(s) that have been deleted.

=item 4

No I<idc> match, one supplemental I<idc> in the second side.
Then this I<idc> correspond to key(s) that have been inserted.

=back

Cases 3 and 4 are simply symetrical, and it is only an interpretation 
to decide whether it is an insert or a delete, taking the first side 
as the reference.

=head2 IMPLEMENTATION ISSUES

The checksum implementation gives integers, which are constant length
and easy to manipulate afterwards.

The xor aggregate is a good choice because there is no overflow issue with it
and it takes into account all bits of the input.

The initial I<idc> checksum column involves an ABS() otherwise
later SQL MOD() of a negative number would give a negative result.

Null values must be taken care appropriatelly.

The folding factor and all modules are taken as power of two, so as 
to ease the retrieval of keys in some case, because then
MOD(MOD(idc, module(p)),module(p+1))=MOD(idc,module(p+1)),
thus one can skip intermediate modulos if necessary.

There is a special management of large chunks of deletes or inserts
which is implemented although not detailed in the algorithmic overview
above nor the complexity analysis below.

=head1 ANALYSIS

Let n be the number of rows, r the row size, f the folding factor
and k the number of differences to be detected. Then ISTM that:

=over 2

=item 1

The network volume complexity is better than k*f*ceil(log(n)/log(f)).
It is independent of r, the lower f the better, and you want k<<n.

=item 2

The maximum number of requests is 6+2*ceil(log(n)/log(f)).
The minimum is 6+ceil(log(n)/log(f)) if the two tables are equal.

=item 3

The disk I/O traffic complexity on the tables is n*r+n*ln(n)*(f/(f-1)).
Here a not too small f is better, as it reduces both the number of 
requests and of disk I/Os; 

=back

The choice of f is indeed a tradeoff.

=head1 REFERENCES

This script and algorithm was somehow inspired by:

=over 2

I<Taming the Distributed Database Problem: A Case Study Using MySQL>
by Giuseppe Maxia in B<Sys Admin> vol 13 num 8, Aug 2004, pp 29-40.
See L<http://www.perlmonks.org/index.pl?node_id=381053> for details.

=back

In the above paper, three algorithms are presented. 
The first one compares two tables with a checksum technique.
The second one finds UPDATE or INSERT differences based on a 2-level 
(checksum and summary) table hierarchy. The algorithm is asymetrical,
as different queries are performed on the two tables to be compared.
It seems that the network traffic volume is in k*(f+(n/f)+r),
that it has a probabilistically-buggy merge procedure, and
that it makes assumptions about the distribution of key values.
The third algorithm looks for DELETE differences based on counting,
with the implicit assumption that there are only delete differences.

The algorithm used here implements all three tasks. It is fully symetrical.
It finds UPDATE, DELETE and INSERT between the two tables. 
The checksum and summary hierarchical level idea is reused and generalized
so as to reduce the algorithmic complexity.

From the implementation standpoint, the script is as parametric 
as possible thru many options, and makes as few assumptions 
as possible about table structures, types and values.

=head1 SEE ALSO

Some products implement such features, as for instance:
L<http://www.programurl.com/software/sql-server-comparison.htm>
L<http://www.dbbalance.com/db_comparison.htm>
L<http://www.dkgas.com/dbdiff.htm>
L<http://www.sql-server-tool.com/index.htm>

=head1 BUGS

All softwares have bugs. This is a software, hence it must have bugs.
Reporting bugs is good practice, so tell me if you find one.

=head1 VERSIONS

See L<http://pgfoundry.org/projects/pg-comparator/> for the latest
version. My personnal site for the tool is 
L<http://www.coelho.net/pg_comparator/>.

=over 4

=item B<version 1.3> 31/08/2004

Project moved to L<http://pgfoundry.org/>.

Use cksum8 checksum function by default.

Minor doc updates.

=item B<version 1.2> 27/08/2004

Added B<--show-all-keys> option for handling big chunks of deletes
or inserts.

=item B<version 1.1> 26/08/2004

Fix algorithmic bug: checksums B<must> also include the key, 
otherwise exchanged data could be not detected if the keys were 
to be grouped together.

Algorithmic section added to manual page.
Thanks to I<Giuseppe Maxia> who asked for it.

Various code cleanups.

=item B<version 1.0> 25/08/2004

Initial revision.

=back

=head1 COPYRIGHT

Copyright (c) 2004, Fabien Coelho <fabien at coelho dot net>

This softwere is distributed under the terms of the BSD Licence. 
Basically, you can do whatever you want, but you have to keep
the license... and I'm not responsible for any consequences. 
Beware, you may lose your data or your hairs because of this software!
See the LICENSE file enclosed with the distribution for details.

=cut

use strict; # I don't like perl;-)
use Getopt::Long;
use DBI;

# various option defaults
my ($factor, $temp, $ask_pass, $verb, $max_report) = (128, 1, 0, 0, 32);
my ($cksum, $agg, $prefix, $sep) = ('cksum8', 'xor', 'cmp', ':');
my $source = 'DBI:Pg:dbname=%b;host=%h;port=%p;';
my $null = "null_string(%s,'null')";
my $show_all_keys = 0;

# self extracting help
# usage(verbosity, exit value, message)
sub usage($$$)
{
    my ($verbose,$stat,$msg) = @_;
    print STDERR "ERROR: $msg\n" if $msg;
    require Pod::Usage;
    Pod::Usage::pod2usage(-verbose => $verbose, -exitval => $stat);
}

# parse a connection string... or many options instead?
# could we directly ask for the DBI connection string?
# ($u,$w,$h,$p,$b,$t,$k,$c) = parse_conn("connection-string")
# globals: $ENV{USER}, $verb
sub parse_conn($)
{
    my $c = shift;
    my $saved = $c;
    my ($user,$pass,$host,$port,$base,$tabl,$keys,$cols) = # set defaults
	($ENV{USER}, '', 'localhost', 5432, $ENV{USER}, '', '', '');

    # parser is pretty rough...
    $c =~ s/^db:(pg:)?//; # ignore start of url tag
    ($user, $pass) = ($1, $3) if $c =~ s/^([\w]+)(:([^\@]*))?\@//i;
    ($host, $port) = ($1, $3) if $c =~ s/^([\w]+)(:(\d+))?//i;
    ($base, $tabl) = ($2, $3) if $c =~ s,^/(\w+)/([\w.]+),,i;
    $tabl = $1 if not $tabl and $c =~ s,^/([\w.]+),,i;
    ($keys, $cols) = ($2, $3) if $tabl and $c =~ s/^\?(([\w,]+):)?([\w,]+)//i;

    my @res = ($user,$pass,$host,$port,$base,$tabl,$keys,$cols);
    die "parse error on '$saved' at '$c'\n@res\n" if $c;
    print "connection parameters: @res\n" if $verb>1;
    return @res;
}

# $dbh = conn($base,$host,$port,$user,$pass)
# globals: $source $verb
sub conn($$$$$)
{
    my ($b,$h,$p,$u,$w,$t) = @_;
    my $s = $source;
    $s =~ s/\%b/$b/g;  $s =~ s/\%h/$h/g;  $s =~ s/\%p/$p/g;  $s =~ s/\%u/$u/g;
    my $dbh = DBI->connect($s, $u, $w, { RaiseError => 1, PrintError => 0 });
    print "# connected to $u\@$h:$p/$b\n" if $verb;
    return $dbh;
}

# $number_of_rows = count($dbh,$table)
sub count($$)
{
    my ($dbh,$table) = @_;
    return $dbh->selectrow_array("SELECT COUNT(*) FROM $table");
}

# @l = null_string(@column_names)
# globals: $null
sub null_string(@)
{
    for my $s (@_) {
	my $n = $null;
	$n =~ s/\%s/$s/g;
	$s = $n;
    }
    return @_;
}

# returns an sql concatenation of fields
# $sql = concat($string_of_comma_separated_fields)
# globals: $sep ($null)
sub concat($)
{
    return join("||'$sep'||",null_string(split(/,/,shift)));
}

# $count = compute_cheksum($dbh,$table,$keys,$cols,$name)
# globals: $temp $cksum $verb ($sep $null)
sub compute_cheksum($$$$$)
{
    my ($dbh,$table,$keys,$cols,$name) = @_;
    print "building checksum table ${name}0\n" if $verb>1;
    $dbh->do("CREATE $temp TABLE ${name}0 AS " .
	     "SELECT " . concat($keys) . " AS id," .
	     # ABS(idc) because of sql MOD may have negative remainder
	     # idc needed to avoid assumptions about keys...
	     " ABS($cksum(" . concat($keys) . ")) AS idc," .
	     " $cksum(" . concat("$keys,$cols") . ") AS cks " . # COUNT+SUM?
	     "FROM $table");
    return count($dbh, "${name}0");
}

# compute_summaries($dbh, $name, @modules)
# globals: $verb $temp $agg
sub compute_summaries($$@)
{
    my ($dbh,$name,@mods) = @_;
    # compute cascade of summary tables
    for my $level (1 .. @mods-1) {
	print "building summary table ${name}$level ($mods[$level])\n" 
	    if $verb>1;
	$dbh->do("CREATE $temp TABLE ${name}${level} AS " .
		 "SELECT MOD(idc,$mods[$level]) AS idc, $agg(cks) AS cks " .
		 "FROM ${name}" . ($level-1) . " " .
		 "GROUP BY MOD(idc,$mods[$level])");
    }
}

# get info for investigated a list of idc (hopefully not too long)
# $sth = selidc($dbh,$table,$module,$get_id,@idc)
sub selidc($$$$@)
{
    my ($dbh,$table,$module,$get_id,@idc) = @_;
    my $sth = 
	$dbh->prepare("SELECT idc, cks" . ($get_id? ", id ": " ") .
		      "FROM $table " .
		      "WHERE MOD(idc,$module) IN (" . join(',', @idc) . ") " .
		      "ORDER BY idc, cks");
    $sth->execute();
    return $sth;
}

# investigate an "idc/module" list to show corresponding keys.
# show_all_keys($dbh, $table, $nature, @idc_mods)
# globals: $verb
sub show_all_keys($$$@)
{
    my ($dbh,$table,$nature,@idc_mods) = @_;
    return unless @idc_mods; # bye if nothing to investigate
    my $cond = ''; # select query condition. must not be empty.
    print "# investigating $nature chunks\n" if $verb;
    for my $idc_mod (@idc_mods) {
	my ($idc,$module) = split '/', $idc_mod;
	$cond .= ' OR ' if $cond;
	$cond .= "MOD(idc,$module)=$idc";
    }
    my $sth = $dbh->prepare("SELECT id FROM $table WHERE $cond ORDER BY id");
    $sth->execute();
    while (my @row = $sth->fetchrow_array()) {
	print "$nature @row\n";
    }
}

# compute differences by climbing up the tree, output result on the fly.
# differences($dbh1, $dbh2, $name1, $name2, @modules)
# globals: $max_report $verb $show_all_keys
sub differences($$$$@)
{
    my ($dbh1, $dbh2, $name1, $name2, @modules) = @_;
    my $level = @modules-1; # number of last summary table
    my $module = 1; # module of previous table
    my (@next_idc, @idc_mod_insert, @idc_mod_delete);
    my @idc = (0);

    while ($level>=0 and @idc)
    {
	if ($max_report && @idc>$max_report) {
	    print "giving up at level $level: too many differences.\n" .
		"\tadjust max option (current is $max_report) to proceed.\n" .
		"\tidc list length is " . scalar @idc . ": @idc\n";
	    return;
	}

	print "investigating @idc, level=$level\n" if $verb>1;
	# select statement handlers
	my $s1 = selidc($dbh1, ${name1}.$level, $module, !$level, @idc); 
	my $s2 = selidc($dbh2, ${name2}.$level, $module, !$level, @idc);
	# content of one row from the above select result
	my (@r1,@r2); 
	
	# let us merge the two ordered select
	while (1)
	{
	    @r1 = $s1->fetchrow_array() unless @r1 or not $s1->{Active};
	    @r2 = $s2->fetchrow_array() unless @r2 or not $s2->{Active};
	    last unless @r1 or @r2;
	    
	    if (@r1 && @r2 && $r1[0]==$r2[0]) { # matching idc
		if ($r1[1] != $r2[1]) { # non matching checksums
		    if ($level) {
			push @next_idc, $r1[0]; # to be investigated...
		    } else {
			print "UPDATE $r1[2]\n"; # final result
		    }
		}
		@r1 = @r2 = ();
	    }
	    elsif ((!@r2) || (@r1 && $r1[0]<$r2[0])) { # more idc in table 1
		if ($level) {
		    push @idc_mod_delete, "$r1[0]/$modules[$#modules]"; # later
		} else {
		    print "DELETE $r1[2]\n"; # final result
		}
		@r1 = ();
	    } 
	    elsif ((!@r1) || (@r2 && $r1[0]>$r2[0])) { # more idc in table 2
		if ($level) {
		    push @idc_mod_insert, "$r2[0]/$modules[$#modules]"; # later
		} else {
		    print "INSERT $r2[2]\n"; # final result
		}
		@r2 = ();
	    }
	}
	$s1->finish(); 	$s2->finish();
	$level--; # next table! 0 is the initial checksum table
	$module = pop @modules; # next module
	@idc = @next_idc; # idcs to be investigated on next round
	@next_idc = ();
    }

    # take care of big chunks of INSERT or DELETE if necessary
    # should never happen in normal "few differences" conditions
    if (@idc_mod_insert) {
	if ($show_all_keys) {
	    show_all_keys($dbh2, "${name2}0", 'INSERT', @idc_mod_insert);
	} else {
	    print "insert chunks: @idc_mod_insert\n";
	}
    }
    if (@idc_mod_delete) {
	if ($show_all_keys) {
	    show_all_keys($dbh1, "${name1}0", 'DELETE', @idc_mod_delete);
	} else {
	    print "delete chunks: @idc_mod_delete\n";
	}
    }
}

# option management
GetOptions("manual|man|m" => sub { usage(2, 0, ''); },
           "options|option|o" => sub { usage(1, 0, ''); },
           "help|h" => sub { usage(0, 0, ''); },
	   "verbose|v+" => \$verb,
	   "checksum-function|cksum|cf|c=s" => \$cksum,
	   "aggregate-function|af|a=s" => \$agg,
	   "factor|f=i" => \$factor,
	   "maximum|x=i" => \$max_report,
	   "null|n=s" => \$null,
	   "prefix|p=s" => \$prefix,
	   "separator|s=s" => \$sep,
	   "source|u=s" => \$source,
	   "temporary|tmp|t!" => \$temp,
	   "show-all-keys|sak|ak!" => \$show_all_keys,
	   "ask-pass|ap!" => \$ask_pass) or die "$! (try $0 --help)";

# fix --temp or --notemp option
$temp = $temp? 'TEMPORARY': '';

# factor MUST BE a power of 2
$factor = 2**int(log($factor)/log(2));
$factor = 2 if $factor<2;

# intermediate table names
my ($name1,$name2) = ("${prefix}_1_", "${prefix}_2_");

# argument management
usage(0,0,'expecting 2 arguments') unless @ARGV == 2;
my ($u1,$w1,$h1,$p1,$b1,$t1,$k1,$c1) = parse_conn(shift);
my ($u2,$w2,$h2,$p2,$b2,$t2,$k2,$c2) = parse_conn(shift);

# fix some default values
$t2 = $t1 unless $t1;  $k2 = $k1 unless $k2;  $c2 = $c1 unless $c2;

if ($ask_pass) {
    require Term::ReadPassword;
    $w1 = Term::ReadPassword::read_password('connection 1 password> ');
    $w2 = Term::ReadPassword::read_password('connection 2 password> ');
}

# let us work...

print "# connecting to database servers...\n" if $verb;
my $dbh1 = conn($b1,$h1,$p1,$u1,$p1);
my $dbh2 = conn($b2,$h2,$p2,$u2,$p2);

print "# building checksum tables and counting rows...\n" if $verb;
my $count1 = compute_cheksum($dbh1, $t1, $k1, $c1, $name1);
my $count2 = compute_cheksum($dbh2, $t2, $k2, $c2, $name2);

print "# computing size and modules after folding factor...\n" if $verb;
my $size = $count1>$count2? $count1: $count2; # max?
my @modules = ($size);
my $module = 2**int(log($size/$factor)/log(2));
while ($module>1) {
    push @modules, $module;
    $module = int($module/$factor);
}
push @modules, 1;

print "# building summary tables...\n" if $verb;
compute_summaries($dbh1, $name1, @modules);
compute_summaries($dbh2, $name2, @modules);

print "# looking for differences...\n" if $verb;
differences($dbh1,$dbh2,$name1,$name2,@modules);

print "# done...\n" if $verb; 
$dbh1->disconnect();  $dbh2->disconnect();
